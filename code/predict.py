import os
import torch
import torch.nn.functional as F
import pandas as pd
import numpy as np
import argparse
from pathlib import Path
from esm import Alphabet, FastaBatchedDataset, ProteinBertModel, pretrained, MSATransformer
from module.PIC import PIC
from typing import List, Dict, Optional


class ProteinPredictor:
    """è›‹ç™½è´¨é‡è¦æ€§é¢„æµ‹å™¨ - æ”¯æŒå•æ¨¡å‹å’Œé›†æˆæ¨¡å‹é¢„æµ‹"""
    
    def __init__(self, model_path=None, esm_model_path='./pretrained_model/esm2_t33_650M_UR50D.pt', 
                 device='cuda:7', ensemble_mode=False, model_dir=None, cell_lines=None):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        Args:
            model_path: å•ä¸ªè®­ç»ƒå¥½çš„PICæ¨¡å‹è·¯å¾„ï¼ˆå•æ¨¡å‹æ¨¡å¼ï¼‰
            esm_model_path: ESM2é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
            device: è®¡ç®—è®¾å¤‡
            ensemble_mode: æ˜¯å¦ä½¿ç”¨é›†æˆæ¨¡å¼
            model_dir: æ¨¡å‹ç›®å½•ï¼ˆé›†æˆæ¨¡å¼ï¼‰
            cell_lines: ç»†èƒç³»åˆ—è¡¨ï¼ˆé›†æˆæ¨¡å¼ï¼‰
        """
        self.device = device
        self.esm_model_path = esm_model_path
        self.ensemble_mode = ensemble_mode
        
        # åŠ è½½ESM2æ¨¡å‹
        print("Loading ESM2 model...")
        self.esm_model, self.alphabet = pretrained.load_model_and_alphabet(esm_model_path)
        self.esm_model.eval()
        if torch.cuda.is_available():
            self.esm_model = self.esm_model.to(device)
        
        if ensemble_mode:
            # é›†æˆæ¨¡å¼ï¼šåŠ è½½å¤šä¸ªæ¨¡å‹
            print("Initializing ensemble mode...")
            self.models = {}
            self.cell_lines = cell_lines or [
                "ARH-77", "IM-9", "KMS-11", "L-363", "LP-1",
                "OCI-AML2", "OCI-AML3", "OCI-LY-19", "OPM-2",
                "ROS-50", "RPMI-8226", "SU-DHL-10", "SU-DHL-5", "SU-DHL-8"
            ]
            self.load_ensemble_models(model_dir)
        else:
            # å•æ¨¡å‹æ¨¡å¼
            print("Loading single PIC model...")
            self.pic_model = PIC(
                input_shape=1280,
                hidden_units=320,
                device=device,
                linear_drop=0.1,
                attn_drop=0.3,
                output_shape=1
            )
            self.pic_model.load_state_dict(torch.load(model_path, map_location=device))
            self.pic_model.to(device)
            self.pic_model.eval()
        
        print("Models loaded successfully!")
    
    def load_ensemble_models(self, model_dir):
        """åŠ è½½é›†æˆæ¨¡å‹"""
        if not model_dir:
            raise ValueError("model_dir is required for ensemble mode")
        
        print(f"Loading ensemble models from {model_dir}...")
        loaded_count = 0
        
        for cell_line in self.cell_lines:
            model_path = os.path.join(model_dir, f"PIC_{cell_line}", f"PIC_{cell_line}_model.pth")
            
            if os.path.exists(model_path):
                try:
                    model = PIC(
                        input_shape=1280,
                        hidden_units=320,
                        device=self.device,
                        linear_drop=0.1,
                        attn_drop=0.3,
                        output_shape=1
                    )
                    model.load_state_dict(torch.load(model_path, map_location=self.device))
                    model.to(self.device)
                    model.eval()
                    
                    self.models[cell_line] = model
                    loaded_count += 1
                    print(f"âœ“ Loaded {cell_line}")
                    
                except Exception as e:
                    print(f"âœ— Failed to load {cell_line}: {e}")
            else:
                print(f"âœ— Model not found: {model_path}")
        
        print(f"Successfully loaded {loaded_count}/{len(self.cell_lines)} models")
        
        if loaded_count == 0:
            raise ValueError("No models loaded successfully")
    
    def extract_sequence_embedding(self, sequence, max_length=1000):
        """
        æå–å•ä¸ªè›‹ç™½è´¨åºåˆ—çš„åµŒå…¥ç‰¹å¾
        
        Args:
            sequence: è›‹ç™½è´¨åºåˆ—å­—ç¬¦ä¸²
            max_length: æœ€å¤§åºåˆ—é•¿åº¦
            
        Returns:
            feature: åºåˆ—åµŒå…¥ç‰¹å¾
            start_padding_idx: å¡«å……å¼€å§‹ä½ç½®
        """
        # æ¸…ç†åºåˆ—
        sequence = sequence.replace('*', '').upper()
        
        # å‡†å¤‡æ•°æ®
        data = [("protein", sequence)]
        batch_converter = self.alphabet.get_batch_converter()
        batch_labels, batch_strs, batch_tokens = batch_converter(data)
        
        batch_tokens = batch_tokens.to(self.device)
        
        # æå–ç‰¹å¾
        with torch.no_grad():
            results = self.esm_model(batch_tokens, repr_layers=[33], return_contacts=False)
            representations = results["representations"][33]
            
            # è·å–åºåˆ—ç‰¹å¾ï¼ˆå»é™¤BOSå’ŒEOS tokenï¼‰
            sequence_length = len(sequence)
            truncate_len = min(max_length, sequence_length)
            feature = representations[0, 1:truncate_len + 1]  # å»é™¤BOS token
            
            # å¤„ç†å¡«å……
            if feature.shape[0] < max_length:
                pad_length = max_length - feature.shape[0]
                zero_features = torch.zeros((pad_length, 1280)).to(self.device)
                feature = torch.cat([feature, zero_features])
                start_padding_idx = torch.tensor(feature.shape[0] - pad_length).to(self.device)
            else:
                feature = feature[:max_length]
                start_padding_idx = torch.tensor(-1).to(self.device)
        
        return feature, start_padding_idx
    
    def predict_single_protein(self, sequence, return_attention=False, voting_strategy='soft'):
        """
        é¢„æµ‹å•ä¸ªè›‹ç™½è´¨çš„é‡è¦æ€§
        
        Args:
            sequence: è›‹ç™½è´¨åºåˆ—
            return_attention: æ˜¯å¦è¿”å›æ³¨æ„åŠ›æƒé‡ï¼ˆä»…å•æ¨¡å‹æ¨¡å¼ï¼‰
            voting_strategy: æŠ•ç¥¨ç­–ç•¥ï¼ˆä»…é›†æˆæ¨¡å¼ï¼‰ï¼š'soft', 'hard'
            
        Returns:
            prediction: é¢„æµ‹æ¦‚ç‡æˆ–é›†æˆç»“æœ
            attention_weights: æ³¨æ„åŠ›æƒé‡ï¼ˆå¯é€‰ï¼‰
        """
        # æå–ç‰¹å¾
        feature, start_padding_idx = self.extract_sequence_embedding(sequence)
        
        # æ·»åŠ batchç»´åº¦
        feature = feature.unsqueeze(0)
        start_padding_idx = start_padding_idx.unsqueeze(0)
        
        if self.ensemble_mode:
            # é›†æˆé¢„æµ‹
            return self._ensemble_predict(feature, start_padding_idx, voting_strategy)
        else:
            # å•æ¨¡å‹é¢„æµ‹
            with torch.no_grad():
                if return_attention:
                    logits, attention_weights = self.pic_model(feature, start_padding_idx, get_attention=True)
                    probability = torch.sigmoid(logits).cpu().numpy()[0, 0]
                    return probability, attention_weights.cpu().numpy()
                else:
                    logits = self.pic_model(feature, start_padding_idx)
                    probability = torch.sigmoid(logits).cpu().numpy()[0, 0]
                    return probability
    
    def _ensemble_predict(self, feature, start_padding_idx, voting_strategy='soft'):
        """æ‰§è¡Œé›†æˆé¢„æµ‹"""
        predictions = []
        probabilities = []
        individual_results = {}
        
        with torch.no_grad():
            for cell_line, model in self.models.items():
                try:
                    logits = model(feature, start_padding_idx)
                    prob = torch.sigmoid(logits).cpu().numpy()[0, 0]
                    pred = 1 if prob > 0.5 else 0
                    
                    predictions.append(pred)
                    probabilities.append(prob)
                    individual_results[cell_line] = {'probability': prob, 'prediction': pred}
                    
                except Exception as e:
                    print(f"Error in prediction for {cell_line}: {e}")
                    continue
        
        if len(probabilities) == 0:
            raise ValueError("No successful predictions from any model")
        
        # é›†æˆé¢„æµ‹
        if voting_strategy == 'soft':
            # è½¯æŠ•ç¥¨ï¼šå¹³å‡æ¦‚ç‡
            ensemble_prob = np.mean(probabilities)
            ensemble_pred = 1 if ensemble_prob > 0.5 else 0
        elif voting_strategy == 'hard':
            # ç¡¬æŠ•ç¥¨ï¼šå¤šæ•°å†³å®š
            ensemble_pred = 1 if sum(predictions) > len(predictions) / 2 else 0
            ensemble_prob = sum(predictions) / len(predictions)
        else:
            raise ValueError(f"Unknown voting strategy: {voting_strategy}")
        
        return {
            'ensemble_probability': ensemble_prob,
            'ensemble_prediction': ensemble_pred,
            'num_models': len(probabilities),
            'voting_strategy': voting_strategy,
            'individual_results': individual_results
        }
    
    def predict_from_fasta(self, fasta_file, output_file=None, return_attention=False, voting_strategy='soft'):
        """
        ä»FASTAæ–‡ä»¶é¢„æµ‹å¤šä¸ªè›‹ç™½è´¨çš„é‡è¦æ€§
        
        Args:
            fasta_file: FASTAæ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            return_attention: æ˜¯å¦è¿”å›æ³¨æ„åŠ›æƒé‡ï¼ˆä»…å•æ¨¡å‹æ¨¡å¼ï¼‰
            voting_strategy: æŠ•ç¥¨ç­–ç•¥ï¼ˆä»…é›†æˆæ¨¡å¼ï¼‰
            
        Returns:
            results_df: é¢„æµ‹ç»“æœDataFrame
        """
        results = []
        
        # è¯»å–FASTAæ–‡ä»¶
        with open(fasta_file, 'r') as f:
            lines = f.readlines()
        
        current_id = None
        current_seq = ""
        
        for line in lines:
            line = line.strip()
            if line.startswith('>'):
                # å¤„ç†å‰ä¸€ä¸ªåºåˆ—
                if current_id is not None:
                    print(f"Predicting {current_id}...")
                    try:
                        if self.ensemble_mode:
                            result = self.predict_single_protein(current_seq, voting_strategy=voting_strategy)
                            results.append({
                                'protein_id': current_id,
                                'sequence': current_seq,
                                'sequence_length': len(current_seq),
                                'essentiality_probability': result['ensemble_probability'],
                                'PES_score': self.calculate_pes(result['ensemble_probability']),
                                'prediction': 'Essential' if result['ensemble_prediction'] else 'Non-essential',
                                'confidence': self._calculate_confidence(result['ensemble_probability']),
                                'voting_strategy': voting_strategy,
                                'num_models': result['num_models']
                            })
                        else:
                            if return_attention:
                                prob, attention = self.predict_single_protein(current_seq, return_attention=True)
                            else:
                                prob = self.predict_single_protein(current_seq)
                            
                            results.append({
                                'protein_id': current_id,
                                'sequence': current_seq,
                                'sequence_length': len(current_seq),
                                'essentiality_probability': prob,
                                'PES_score': self.calculate_pes(prob),
                                'prediction': 'Essential' if prob > 0.5 else 'Non-essential',
                                'confidence': self._calculate_confidence(prob)
                            })
                    except Exception as e:
                        print(f"Error predicting {current_id}: {e}")
                        results.append({
                            'protein_id': current_id,
                            'sequence': current_seq,
                            'sequence_length': len(current_seq),
                            'essentiality_probability': np.nan,
                            'PES_score': np.nan,
                            'prediction': 'Error',
                            'confidence': 'N/A'
                        })
                
                # å¼€å§‹æ–°åºåˆ—
                current_id = line[1:]
                current_seq = ""
            else:
                current_seq += line
        
        # å¤„ç†æœ€åä¸€ä¸ªåºåˆ—
        if current_id is not None:
            print(f"Predicting {current_id}...")
            try:
                if self.ensemble_mode:
                    result = self.predict_single_protein(current_seq, voting_strategy=voting_strategy)
                    results.append({
                        'protein_id': current_id,
                        'sequence': current_seq,
                        'sequence_length': len(current_seq),
                        'essentiality_probability': result['ensemble_probability'],
                        'PES_score': self.calculate_pes(result['ensemble_probability']),
                        'prediction': 'Essential' if result['ensemble_prediction'] else 'Non-essential',
                        'confidence': self._calculate_confidence(result['ensemble_probability']),
                        'voting_strategy': voting_strategy,
                        'num_models': result['num_models']
                    })
                else:
                    if return_attention:
                        prob, attention = self.predict_single_protein(current_seq, return_attention=True)
                    else:
                        prob = self.predict_single_protein(current_seq)
                    
                    results.append({
                        'protein_id': current_id,
                        'sequence': current_seq,
                        'sequence_length': len(current_seq),
                        'essentiality_probability': prob,
                        'PES_score': self.calculate_pes(prob),
                        'prediction': 'Essential' if prob > 0.5 else 'Non-essential',
                        'confidence': self._calculate_confidence(prob)
                    })
            except Exception as e:
                print(f"Error predicting {current_id}: {e}")
                results.append({
                    'protein_id': current_id,
                    'sequence': current_seq,
                    'sequence_length': len(current_seq),
                    'essentiality_probability': np.nan,
                    'PES_score': np.nan,
                    'prediction': 'Error',
                    'confidence': 'N/A'
                })
        
        # åˆ›å»ºDataFrame
        results_df = pd.DataFrame(results)
        
        # ä¿å­˜ç»“æœ
        if output_file:
            results_df.to_csv(output_file, index=False)
            print(f"Results saved to {output_file}")
        
        return results_df
    
    def _calculate_confidence(self, probability):
        """è®¡ç®—ç½®ä¿¡åº¦"""
        return 'High' if abs(probability - 0.5) > 0.3 else 'Medium' if abs(probability - 0.5) > 0.1 else 'Low'
    
    def calculate_pes(self, probability):
        """
        è®¡ç®—è›‹ç™½è´¨é‡è¦æ€§åˆ†æ•° (PES)ã€‚
        æ ¹æ®è®ºæ–‡å®šä¹‰ï¼ŒPES ç›´æ¥ç­‰äºæ¨¡å‹ sigmoid è¾“å‡ºçš„æ¦‚ç‡å€¼ (0~1)ã€‚

        Args:
            probability: é‡è¦æ€§æ¦‚ç‡ (0~1)

        Returns:
            float: PES åˆ†æ•°ï¼Œä¸è¾“å…¥æ¦‚ç‡ç›¸åŒã€‚
        """
        return float(probability)
    
    def analyze_biomarkers(self, results_df, pes_threshold=0.9):
        """
        åˆ†ææ½œåœ¨çš„ç”Ÿç‰©æ ‡å¿—ç‰©
        
        Args:
            results_df: é¢„æµ‹ç»“æœDataFrame
            pes_threshold: PESåˆ†æ•°é˜ˆå€¼
            
        Returns:
            biomarkers_df: æ½œåœ¨ç”Ÿç‰©æ ‡å¿—ç‰©DataFrame
        """
        # ç­›é€‰é«˜PESåˆ†æ•°çš„è›‹ç™½è´¨ä½œä¸ºæ½œåœ¨ç”Ÿç‰©æ ‡å¿—ç‰©
        biomarkers = results_df[
            (results_df['PES_score'] >= pes_threshold) & 
            (results_df['confidence'] == 'High')
        ].copy()
        
        # æŒ‰PESåˆ†æ•°æ’åº
        biomarkers = biomarkers.sort_values('PES_score', ascending=False)
        
        # æ·»åŠ ç”Ÿç‰©æ ‡å¿—ç‰©ç­‰çº§
        biomarkers['biomarker_grade'] = pd.cut(
            biomarkers['PES_score'],
            bins=[0, 0.6, 0.8, 0.95, float('inf')],
            labels=['Low', 'Medium', 'High', 'Very High']
        )
        
        return biomarkers


def main():
    parser = argparse.ArgumentParser(description='Predict protein essentiality using trained PIC model(s)')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--input_fasta', type=str, required=True,
                       help='Input FASTA file with protein sequences')
    parser.add_argument('--output_file', type=str, 
                       help='Output CSV file for results')
    parser.add_argument('--device', type=str, default='cuda:7',
                       help='Device to use (cuda:7, cpu, etc.)')
    parser.add_argument('--esm_model_path', type=str, 
                       default='./pretrained_model/esm2_t33_650M_UR50D.pt',
                       help='Path to ESM2 pretrained model')
    
    # æ¨¡å‹é€‰æ‹©
    model_group = parser.add_mutually_exclusive_group(required=True)
    model_group.add_argument('--model_path', type=str,
                           help='Path to single trained PIC model (.pth file)')
    model_group.add_argument('--ensemble_mode', action='store_true',
                           help='Use ensemble of immune cell line models')
    
    # é›†æˆæ¨¡å¼å‚æ•°
    parser.add_argument('--model_dir', type=str, default='result/model_train_results',
                       help='Directory containing trained models (for ensemble mode)')
    parser.add_argument('--cell_lines', type=str, nargs='+',
                       help='Specific cell lines for ensemble (default: 14 immune cell lines)')
    parser.add_argument('--voting_strategy', type=str, default='soft', choices=['soft', 'hard'],
                       help='Voting strategy for ensemble mode')
    
    # åˆ†æå‚æ•°
    parser.add_argument('--pes_threshold', type=float, default=0.9,
                       help='PES (probability) threshold for biomarker analysis')
    parser.add_argument('--biomarker_analysis', action='store_true',
                       help='Perform biomarker analysis')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input_fasta):
        print(f"Error: Input FASTA file {args.input_fasta} not found!")
        return
    
    if args.model_path and not os.path.exists(args.model_path):
        print(f"Error: Model file {args.model_path} not found!")
        return
    
    # è®¾ç½®è¾“å‡ºæ–‡ä»¶
    if not args.output_file:
        base_name = Path(args.input_fasta).stem
        mode_suffix = "ensemble" if args.ensemble_mode else "single"
        args.output_file = f"{base_name}_predictions_{mode_suffix}.csv"
    
    # åˆå§‹åŒ–é¢„æµ‹å™¨
    if args.ensemble_mode:
        print("Initializing ensemble predictor with immune cell line models...")
        predictor = ProteinPredictor(
            esm_model_path=args.esm_model_path,
            device=args.device,
            ensemble_mode=True,
            model_dir=args.model_dir,
            cell_lines=args.cell_lines
        )
    else:
        print("Initializing single model predictor...")
        predictor = ProteinPredictor(
            model_path=args.model_path,
            esm_model_path=args.esm_model_path,
            device=args.device,
            ensemble_mode=False
        )
    
    # è¿›è¡Œé¢„æµ‹
    print("Starting prediction...")
    if args.ensemble_mode:
        results_df = predictor.predict_from_fasta(
            fasta_file=args.input_fasta,
            output_file=args.output_file,
            voting_strategy=args.voting_strategy
        )
    else:
        results_df = predictor.predict_from_fasta(
            fasta_file=args.input_fasta,
            output_file=args.output_file
        )
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n=== Prediction Summary ===")
    print(f"Total proteins: {len(results_df)}")
    print(f"Essential proteins: {len(results_df[results_df['prediction'] == 'Essential'])}")
    print(f"Non-essential proteins: {len(results_df[results_df['prediction'] == 'Non-essential'])}")
    print(f"Average PES score: {results_df['PES_score'].mean():.3f}")
    print(f"Max PES score: {results_df['PES_score'].max():.3f}")

    if args.ensemble_mode:
        print(f"Voting strategy: {args.voting_strategy}")
        print(f"Number of models: {results_df['num_models'].iloc[0] if len(results_df) > 0 else 0}")

    # æ·»åŠ "äº¤é€šç¯"æ ‡è®°åˆ—
    def traffic_light(row):
        if row.prediction == 'Essential':
            return 'ğŸŸ¢' if row.confidence == 'High' else 'ğŸŸ¡'
        else:
            return 'ğŸ”´' if row.confidence == 'High' else 'ğŸŸ '

    results_df['flag'] = results_df.apply(traffic_light, axis=1)
    results_df.to_csv(args.output_file, index=False)

    # ç”Ÿç‰©æ ‡å¿—ç‰©åˆ†æ
    if args.biomarker_analysis:
        print("\n=== Biomarker Analysis ===")
        biomarkers_df = predictor.analyze_biomarkers(results_df, args.pes_threshold)
        
        if len(biomarkers_df) > 0:
            print(f"Potential biomarkers (PES >= {args.pes_threshold}): {len(biomarkers_df)}")
            print("\nTop 10 potential biomarkers:")
            print(biomarkers_df[['protein_id', 'PES_score', 'biomarker_grade']].head(10))
            
            # ä¿å­˜ç”Ÿç‰©æ ‡å¿—ç‰©ç»“æœ
            biomarker_file = args.output_file.replace('.csv', '_biomarkers.csv')
            biomarkers_df.to_csv(biomarker_file, index=False)
            print(f"Biomarker results saved to {biomarker_file}")
        else:
            print(f"No potential biomarkers found with PES >= {args.pes_threshold}")
    
    print("\nPrediction completed!")


if __name__ == '__main__':
    main() 