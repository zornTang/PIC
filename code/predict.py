import os
import torch
import torch.nn.functional as F
import pandas as pd
import numpy as np
import argparse
from pathlib import Path
from esm import Alphabet, FastaBatchedDataset, ProteinBertModel, pretrained, MSATransformer
from module.PIC import PIC


class ProteinPredictor:
    """è›‹ç™½è´¨é‡è¦æ€§é¢„æµ‹å™¨"""
    
    def __init__(self, model_path, esm_model_path, device='cuda:0'):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        Args:
            model_path: è®­ç»ƒå¥½çš„PICæ¨¡å‹è·¯å¾„
            esm_model_path: ESM2é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
            device: è®¡ç®—è®¾å¤‡
        """
        self.device = device
        self.esm_model_path = esm_model_path
        
        # åŠ è½½ESM2æ¨¡å‹
        print("Loading ESM2 model...")
        self.esm_model, self.alphabet = pretrained.load_model_and_alphabet(esm_model_path)
        self.esm_model.eval()
        if torch.cuda.is_available():
            self.esm_model = self.esm_model.to(device)
        
        # åŠ è½½è®­ç»ƒå¥½çš„PICæ¨¡å‹
        print("Loading PIC model...")
        self.pic_model = PIC(
            input_shape=1280,
            hidden_units=320,
            device=device,
            linear_drop=0.1,
            attn_drop=0.3,
            output_shape=1
        )
        self.pic_model.load_state_dict(torch.load(model_path, map_location=device))
        self.pic_model.to(device)
        self.pic_model.eval()
        
        print("Models loaded successfully!")
    
    def extract_sequence_embedding(self, sequence, max_length=1000):
        """
        æå–å•ä¸ªè›‹ç™½è´¨åºåˆ—çš„åµŒå…¥ç‰¹å¾
        
        Args:
            sequence: è›‹ç™½è´¨åºåˆ—å­—ç¬¦ä¸²
            max_length: æœ€å¤§åºåˆ—é•¿åº¦
            
        Returns:
            feature: åºåˆ—åµŒå…¥ç‰¹å¾
            start_padding_idx: å¡«å……å¼€å§‹ä½ç½®
        """
        # æ¸…ç†åºåˆ—
        sequence = sequence.replace('*', '').upper()
        
        # å‡†å¤‡æ•°æ®
        data = [("protein", sequence)]
        batch_converter = self.alphabet.get_batch_converter()
        batch_labels, batch_strs, batch_tokens = batch_converter(data)
        
        batch_tokens = batch_tokens.to(self.device)
        
        # æå–ç‰¹å¾
        with torch.no_grad():
            results = self.esm_model(batch_tokens, repr_layers=[33], return_contacts=False)
            representations = results["representations"][33]
            
            # è·å–åºåˆ—ç‰¹å¾ï¼ˆå»é™¤BOSå’ŒEOS tokenï¼‰
            sequence_length = len(sequence)
            truncate_len = min(max_length, sequence_length)
            feature = representations[0, 1:truncate_len + 1]  # å»é™¤BOS token
            
            # å¤„ç†å¡«å……
            if feature.shape[0] < max_length:
                pad_length = max_length - feature.shape[0]
                zero_features = torch.zeros((pad_length, 1280)).to(self.device)
                feature = torch.cat([feature, zero_features])
                start_padding_idx = torch.tensor(feature.shape[0] - pad_length).to(self.device)
            else:
                feature = feature[:max_length]
                start_padding_idx = torch.tensor(-1).to(self.device)
        
        return feature, start_padding_idx
    
    def predict_single_protein(self, sequence, return_attention=False):
        """
        é¢„æµ‹å•ä¸ªè›‹ç™½è´¨çš„é‡è¦æ€§
        
        Args:
            sequence: è›‹ç™½è´¨åºåˆ—
            return_attention: æ˜¯å¦è¿”å›æ³¨æ„åŠ›æƒé‡
            
        Returns:
            prediction: é¢„æµ‹æ¦‚ç‡
            attention_weights: æ³¨æ„åŠ›æƒé‡ï¼ˆå¯é€‰ï¼‰
        """
        # æå–ç‰¹å¾
        feature, start_padding_idx = self.extract_sequence_embedding(sequence)
        
        # æ·»åŠ batchç»´åº¦
        feature = feature.unsqueeze(0)
        start_padding_idx = start_padding_idx.unsqueeze(0)
        
        # é¢„æµ‹
        with torch.no_grad():
            if return_attention:
                logits, attention_weights = self.pic_model(feature, start_padding_idx, get_attention=True)
                probability = torch.sigmoid(logits).cpu().numpy()[0, 0]
                return probability, attention_weights.cpu().numpy()
            else:
                logits = self.pic_model(feature, start_padding_idx)
                probability = torch.sigmoid(logits).cpu().numpy()[0, 0]
                return probability
    
    def predict_from_fasta(self, fasta_file, output_file=None, return_attention=False):
        """
        ä»FASTAæ–‡ä»¶é¢„æµ‹å¤šä¸ªè›‹ç™½è´¨çš„é‡è¦æ€§
        
        Args:
            fasta_file: FASTAæ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            return_attention: æ˜¯å¦è¿”å›æ³¨æ„åŠ›æƒé‡
            
        Returns:
            results_df: é¢„æµ‹ç»“æœDataFrame
        """
        results = []
        
        # è¯»å–FASTAæ–‡ä»¶
        with open(fasta_file, 'r') as f:
            lines = f.readlines()
        
        current_id = None
        current_seq = ""
        
        for line in lines:
            line = line.strip()
            if line.startswith('>'):
                # å¤„ç†å‰ä¸€ä¸ªåºåˆ—
                if current_id is not None:
                    print(f"Predicting {current_id}...")
                    try:
                        if return_attention:
                            prob, attention = self.predict_single_protein(current_seq, return_attention=True)
                            results.append({
                                'protein_id': current_id,
                                'sequence': current_seq,
                                'sequence_length': len(current_seq),
                                'essentiality_probability': prob,
                                'PES_score': self.calculate_pes(prob),
                                'prediction': 'Essential' if prob > 0.5 else 'Non-essential',
                                'confidence': 'High' if abs(prob - 0.5) > 0.3 else 'Medium' if abs(prob - 0.5) > 0.1 else 'Low'
                            })
                        else:
                            prob = self.predict_single_protein(current_seq)
                            results.append({
                                'protein_id': current_id,
                                'sequence': current_seq,
                                'sequence_length': len(current_seq),
                                'essentiality_probability': prob,
                                'PES_score': self.calculate_pes(prob),
                                'prediction': 'Essential' if prob > 0.5 else 'Non-essential',
                                'confidence': 'High' if abs(prob - 0.5) > 0.3 else 'Medium' if abs(prob - 0.5) > 0.1 else 'Low'
                            })
                    except Exception as e:
                        print(f"Error predicting {current_id}: {e}")
                        results.append({
                            'protein_id': current_id,
                            'sequence': current_seq,
                            'sequence_length': len(current_seq),
                            'essentiality_probability': np.nan,
                            'PES_score': np.nan,
                            'prediction': 'Error',
                            'confidence': 'N/A'
                        })
                
                # å¼€å§‹æ–°åºåˆ—
                current_id = line[1:]
                current_seq = ""
            else:
                current_seq += line
        
        # å¤„ç†æœ€åä¸€ä¸ªåºåˆ—
        if current_id is not None:
            print(f"Predicting {current_id}...")
            try:
                if return_attention:
                    prob, attention = self.predict_single_protein(current_seq, return_attention=True)
                else:
                    prob = self.predict_single_protein(current_seq)
                
                results.append({
                    'protein_id': current_id,
                    'sequence': current_seq,
                    'sequence_length': len(current_seq),
                    'essentiality_probability': prob,
                    'PES_score': self.calculate_pes(prob),
                    'prediction': 'Essential' if prob > 0.5 else 'Non-essential',
                    'confidence': 'High' if abs(prob - 0.5) > 0.3 else 'Medium' if abs(prob - 0.5) > 0.1 else 'Low'
                })
            except Exception as e:
                print(f"Error predicting {current_id}: {e}")
                results.append({
                    'protein_id': current_id,
                    'sequence': current_seq,
                    'sequence_length': len(current_seq),
                    'essentiality_probability': np.nan,
                    'PES_score': np.nan,
                    'prediction': 'Error',
                    'confidence': 'N/A'
                })
        
        # åˆ›å»ºDataFrame
        results_df = pd.DataFrame(results)
        
        # ä¿å­˜ç»“æœ
        if output_file:
            results_df.to_csv(output_file, index=False)
            print(f"Results saved to {output_file}")
        
        return results_df
    
    def calculate_pes(self, probability):
        """
        è®¡ç®—è›‹ç™½è´¨é‡è¦æ€§åˆ†æ•° (PES)ã€‚
        æ ¹æ®è®ºæ–‡å®šä¹‰ï¼ŒPES ç›´æ¥ç­‰äºæ¨¡å‹ sigmoid è¾“å‡ºçš„æ¦‚ç‡å€¼ (0~1)ã€‚

        Args:
            probability: é‡è¦æ€§æ¦‚ç‡ (0~1)

        Returns:
            float: PES åˆ†æ•°ï¼Œä¸è¾“å…¥æ¦‚ç‡ç›¸åŒã€‚
        """
        return float(probability)
    
    def analyze_biomarkers(self, results_df, pes_threshold=0.9):
        """
        åˆ†ææ½œåœ¨çš„ç”Ÿç‰©æ ‡å¿—ç‰©
        
        Args:
            results_df: é¢„æµ‹ç»“æœDataFrame
            pes_threshold: PESåˆ†æ•°é˜ˆå€¼
            
        Returns:
            biomarkers_df: æ½œåœ¨ç”Ÿç‰©æ ‡å¿—ç‰©DataFrame
        """
        # ç­›é€‰é«˜PESåˆ†æ•°çš„è›‹ç™½è´¨ä½œä¸ºæ½œåœ¨ç”Ÿç‰©æ ‡å¿—ç‰©
        biomarkers = results_df[
            (results_df['PES_score'] >= pes_threshold) & 
            (results_df['confidence'] == 'High')
        ].copy()
        
        # æŒ‰PESåˆ†æ•°æ’åº
        biomarkers = biomarkers.sort_values('PES_score', ascending=False)
        
        # æ·»åŠ ç”Ÿç‰©æ ‡å¿—ç‰©ç­‰çº§
        biomarkers['biomarker_grade'] = pd.cut(
            biomarkers['PES_score'],
            bins=[0, 0.6, 0.8, 0.95, float('inf')],
            labels=['Low', 'Medium', 'High', 'Very High']
        )
        
        return biomarkers


def main():
    parser = argparse.ArgumentParser(description='Predict protein essentiality using trained PIC model')
    parser.add_argument('--model_path', type=str, required=True, 
                       help='Path to trained PIC model (.pth file)')
    parser.add_argument('--esm_model_path', type=str, 
                       default='./pretrained_model/esm2_t33_650M_UR50D.pt',
                       help='Path to ESM2 pretrained model')
    parser.add_argument('--input_fasta', type=str, required=True,
                       help='Input FASTA file with protein sequences')
    parser.add_argument('--output_file', type=str, 
                       help='Output CSV file for results')
    parser.add_argument('--device', type=str, default='cuda:7',
                       help='Device to use (cuda:0, cpu, etc.)')
    parser.add_argument('--pes_threshold', type=float, default=0.9,
                       help='PES (probability) threshold for biomarker analysis')
    parser.add_argument('--biomarker_analysis', action='store_true',
                       help='Perform biomarker analysis')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input_fasta):
        print(f"Error: Input FASTA file {args.input_fasta} not found!")
        return
    
    if not os.path.exists(args.model_path):
        print(f"Error: Model file {args.model_path} not found!")
        return
    
    # è®¾ç½®è¾“å‡ºæ–‡ä»¶
    if not args.output_file:
        base_name = Path(args.input_fasta).stem
        args.output_file = f"{base_name}_predictions.csv"
    
    # åˆå§‹åŒ–é¢„æµ‹å™¨
    predictor = ProteinPredictor(
        model_path=args.model_path,
        esm_model_path=args.esm_model_path,
        device=args.device
    )
    
    # è¿›è¡Œé¢„æµ‹
    print("Starting prediction...")
    results_df = predictor.predict_from_fasta(
        fasta_file=args.input_fasta,
        output_file=args.output_file
    )
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n=== Prediction Summary ===")
    print(f"Total proteins: {len(results_df)}")
    print(f"Essential proteins: {len(results_df[results_df['prediction'] == 'Essential'])}")
    print(f"Non-essential proteins: {len(results_df[results_df['prediction'] == 'Non-essential'])}")
    print(f"Average PES score: {results_df['PES_score'].mean():.3f}")
    print(f"Max PES score: {results_df['PES_score'].max():.3f}")

    # æ·»åŠ â€œäº¤é€šç¯â€æ ‡è®°åˆ—ï¼Œå¹¶è¦†ç›–ä¿å­˜å¸¦ flag çš„ç»“æœæ–‡ä»¶
    def traffic_light(row):
        if row.prediction == 'Essential':
            return 'ğŸŸ¢' if row.confidence == 'High' else 'ğŸŸ¡'
        else:
            return 'ğŸ”´' if row.confidence == 'High' else 'ğŸŸ '

    results_df['flag'] = results_df.apply(traffic_light, axis=1)
    results_df.to_csv(args.output_file, index=False)

    # ç”Ÿç‰©æ ‡å¿—ç‰©åˆ†æ
    if args.biomarker_analysis:
        print("\n=== Biomarker Analysis ===")
        biomarkers_df = predictor.analyze_biomarkers(results_df, args.pes_threshold)
        
        if len(biomarkers_df) > 0:
            print(f"Potential biomarkers (PES >= {args.pes_threshold}): {len(biomarkers_df)}")
            print("\nTop 10 potential biomarkers:")
            print(biomarkers_df[['protein_id', 'PES_score', 'biomarker_grade']].head(10))
            
            # ä¿å­˜ç”Ÿç‰©æ ‡å¿—ç‰©ç»“æœ
            biomarker_file = args.output_file.replace('.csv', '_biomarkers.csv')
            biomarkers_df.to_csv(biomarker_file, index=False)
            print(f"Biomarker results saved to {biomarker_file}")
        else:
            print(f"No potential biomarkers found with PES >= {args.pes_threshold}")
    
    print("\nPrediction completed!")


if __name__ == '__main__':
    main() 