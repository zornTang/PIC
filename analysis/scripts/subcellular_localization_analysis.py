#!/usr/bin/env python3
"""
äºšç»†èƒå®šä½å’ŒGOç»†èƒç»„åˆ†å¯Œé›†åˆ†æ
åˆ†æä¸åŒè›‹ç™½è´¨ç»„åˆ«çš„äºšç»†èƒå®šä½å·®å¼‚
å‚è€ƒcompare_predictions.pyçš„ç›®å½•ç»“æ„
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
from collections import defaultdict, Counter
from scipy.stats import fisher_exact
from statsmodels.stats.multitest import multipletests
import warnings
import os
import re
warnings.filterwarnings('ignore')

# è®¾ç½®å¯è§†åŒ–æ ·å¼
plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans', 'Liberation Sans', 'sans-serif']
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['font.size'] = 10

# è›‹ç™½è´¨ç»„åˆ«é¢œè‰²
COLORS = {
    'Commonly Essential': '#E64B35',
    'Human-Specific Essential': '#4DBBD5',
    'Immune-Specific Essential': '#00A087',
    'Commonly Non-essential': '#F39B7F'
}

def load_data():
    """åŠ è½½è›‹ç™½è´¨åˆ†ç»„å’ŒUniProtæ³¨é‡Šæ•°æ®"""
    print("ğŸ“Š Loading data...")

    try:
        # åŠ è½½è›‹ç™½è´¨å››åˆ†ç»„æ•°æ®
        protein_groups = pd.read_csv('../data/neutrophil_four_group_classification.csv')

        # æå–UniProt ID
        uniprot_pattern = r'UniProt:([A-Z0-9]+)'
        protein_groups['uniprot_id'] = protein_groups['protein_id'].str.extract(uniprot_pattern)
        protein_groups = protein_groups.dropna(subset=['uniprot_id'])

        # åŠ è½½UniProtè¯¦ç»†æ³¨é‡Š
        with open('../../data_processing/processed_data/uniprot_annotations/neutrophil_uniprot_detailed.json', 'r') as f:
            uniprot_annotations = json.load(f)

        print(f"âœ“ Loaded {len(protein_groups)} protein groups")
        print(f"âœ“ Loaded {len(uniprot_annotations)} UniProt annotations")

        return protein_groups, uniprot_annotations

    except Exception as e:
        print(f"âŒ Error loading data: {e}")
        return None, None

def process_localization_data(protein_groups, uniprot_annotations):
    """å¤„ç†äºšç»†èƒå®šä½æ•°æ®"""
    print("ğŸ” Processing subcellular localization data...")

    # åˆ›å»ºUniProt IDåˆ°æ³¨é‡Šçš„æ˜ å°„
    uniprot_dict = {item['uniprot_id']: item for item in uniprot_annotations}

    # åˆå¹¶æ•°æ®
    localization_records = []

    for _, row in protein_groups.iterrows():
        uniprot_id = row['uniprot_id']
        group = row['group']

        if uniprot_id in uniprot_dict:
            annotation = uniprot_dict[uniprot_id]

            # äºšç»†èƒå®šä½
            subcellular_location = annotation.get('subcellular_location', '')

            # GOç»†èƒç»„åˆ†
            go_cellular_component = annotation.get('go_cellular_component', [])

            localization_records.append({
                'uniprot_id': uniprot_id,
                'group': group,
                'subcellular_location': subcellular_location,
                'go_cellular_component': go_cellular_component
            })

    localization_data = pd.DataFrame(localization_records)

    # ç»Ÿè®¡ä¿¡æ¯
    total_proteins = len(localization_data)
    with_subcellular = len(localization_data[localization_data['subcellular_location'] != ''])
    with_go_cc = len(localization_data[localization_data['go_cellular_component'].apply(len) > 0])

    print(f"âœ“ Processed {total_proteins} proteins")
    print(f"âœ“ With subcellular location: {with_subcellular} ({with_subcellular/total_proteins*100:.1f}%)")
    print(f"âœ“ With GO cellular component: {with_go_cc} ({with_go_cc/total_proteins*100:.1f}%)")

    return localization_data

def analyze_subcellular_distribution(localization_data):
    """åˆ†æäºšç»†èƒå®šä½åˆ†å¸ƒ"""
    print("ğŸ“ Analyzing subcellular localization distribution...")

    # è¿‡æ»¤æœ‰å®šä½ä¿¡æ¯çš„è›‹ç™½è´¨
    data_with_loc = localization_data[localization_data['subcellular_location'] != ''].copy()

    if len(data_with_loc) == 0:
        print("âŒ No subcellular localization information found")
        return None

    # ç»Ÿè®¡å„ç»„åˆ«çš„å®šä½åˆ†å¸ƒ
    location_stats = {}
    group_totals = {}

    for group in data_with_loc['group'].unique():
        group_data = data_with_loc[data_with_loc['group'] == group]
        group_totals[group] = len(group_data)

        # ç»Ÿè®¡å®šä½
        locations = group_data['subcellular_location'].value_counts()
        location_stats[group] = locations

    print(f"âœ“ Found {len(data_with_loc)} proteins with subcellular localization")

    return {
        'data': data_with_loc,
        'stats': location_stats,
        'totals': group_totals
    }

def analyze_go_cellular_component_enrichment(localization_data):
    """GOç»†èƒç»„åˆ†å¯Œé›†åˆ†æ"""
    print("ğŸ§¬ Performing GO cellular component enrichment analysis...")

    # è¿‡æ»¤æœ‰GOç»†èƒç»„åˆ†ä¿¡æ¯çš„è›‹ç™½è´¨
    data_with_go = localization_data[
        localization_data['go_cellular_component'].apply(len) > 0
    ].copy()

    if len(data_with_go) == 0:
        print("âŒ No GO cellular component information found")
        return None

    # æ”¶é›†æ‰€æœ‰GOç»†èƒç»„åˆ†term
    all_go_terms = Counter()
    group_go_terms = defaultdict(lambda: defaultdict(int))

    for _, row in data_with_go.iterrows():
        group = row['group']
        go_terms = row['go_cellular_component']

        for term in go_terms:
            if isinstance(term, dict) and 'id' in term:
                go_id = term['id']
                all_go_terms[go_id] += 1
                group_go_terms[group][go_id] += 1
            elif isinstance(term, str):
                all_go_terms[term] += 1
                group_go_terms[group][term] += 1

    # ç­›é€‰é¢‘ç‡è¾ƒé«˜çš„GO termï¼ˆè‡³å°‘åœ¨5ä¸ªè›‹ç™½è´¨ä¸­å‡ºç°ï¼‰
    frequent_terms = {term for term, count in all_go_terms.items() if count >= 5}

    if not frequent_terms:
        print("âŒ No frequent GO cellular component terms found")
        return None

    # å¯Œé›†åˆ†æ
    enrichment_results = []
    groups = data_with_go['group'].unique()

    # è®¡ç®—èƒŒæ™¯
    background_total = len(data_with_go)

    for group in groups:
        group_data = data_with_go[data_with_go['group'] == group]
        group_total = len(group_data)

        if group_total < 5:  # è·³è¿‡æ ·æœ¬å¤ªå°‘çš„ç»„
            continue

        for term in frequent_terms:
            # è®¡ç®—è¯¥ç»„ä¸­æœ‰æ­¤termçš„è›‹ç™½è´¨æ•°é‡
            group_with_term = group_go_terms[group].get(term, 0)
            group_without_term = group_total - group_with_term

            # è®¡ç®—èƒŒæ™¯ä¸­æœ‰æ­¤termçš„è›‹ç™½è´¨æ•°é‡
            background_with_term = all_go_terms[term]
            background_without_term = background_total - background_with_term

            if group_with_term == 0:
                continue

            # Fisherç²¾ç¡®æ£€éªŒ
            contingency_table = [
                [group_with_term, group_without_term],
                [background_with_term - group_with_term,
                 background_without_term - group_without_term]
            ]

            try:
                odds_ratio, p_value = fisher_exact(contingency_table, alternative='greater')

                # è®¡ç®—å¯Œé›†å€æ•°
                group_rate = group_with_term / group_total
                background_rate = background_with_term / background_total
                fold_enrichment = group_rate / background_rate if background_rate > 0 else float('inf')

                enrichment_results.append({
                    'group': group,
                    'go_term': term,
                    'group_with_term': group_with_term,
                    'group_total': group_total,
                    'background_with_term': background_with_term,
                    'background_total': background_total,
                    'odds_ratio': odds_ratio,
                    'p_value': p_value,
                    'fold_enrichment': fold_enrichment,
                    'group_rate': group_rate,
                    'background_rate': background_rate
                })

            except Exception as e:
                continue

    if not enrichment_results:
        print("âŒ No enrichment results generated")
        return None

    # è½¬æ¢ä¸ºDataFrameå¹¶è¿›è¡Œå¤šé‡æ£€éªŒæ ¡æ­£
    enrichment_df = pd.DataFrame(enrichment_results)

    # å¤šé‡æ£€éªŒæ ¡æ­£
    _, corrected_p, _, _ = multipletests(enrichment_df['p_value'], method='fdr_bh')
    enrichment_df['adj_p_value'] = corrected_p

    # ç­›é€‰æ˜¾è‘—å¯Œé›†çš„ç»“æœ
    significant_results = enrichment_df[
        (enrichment_df['adj_p_value'] < 0.05) &
        (enrichment_df['fold_enrichment'] > 1.5) &
        (enrichment_df['group_with_term'] >= 3)
    ].sort_values(['group', 'adj_p_value'])

    print(f"âœ“ Analyzed {len(frequent_terms)} GO cellular component terms")
    print(f"âœ“ Found {len(significant_results)} significantly enriched terms")

    return {
        'all_results': enrichment_df,
        'significant_results': significant_results
    }

def create_subcellular_heatmap(subcellular_results):
    """åˆ›å»ºäºšç»†èƒå®šä½çƒ­å›¾"""
    if not subcellular_results:
        return

    print("ğŸ¨ Creating subcellular localization heatmap...")

    stats = subcellular_results['stats']
    totals = subcellular_results['totals']

    # åªä¿ç•™å¿…éœ€è›‹ç™½è´¨ç»„åˆ«ï¼Œæ’é™¤å…±åŒéå¿…éœ€
    essential_groups = [
        'Commonly Essential',
        'Human-Specific Essential',
        'Immune-Specific Essential'
    ]

    # è¿‡æ»¤å‡ºå¿…éœ€ç»„åˆ«çš„æ•°æ®
    filtered_stats = {group: stats[group] for group in essential_groups if group in stats}
    filtered_totals = {group: totals[group] for group in essential_groups if group in totals}

    if not filtered_stats:
        print("âŒ No essential protein groups found")
        return

    # è·å–æ‰€æœ‰å®šä½ç±»å‹
    all_locations = set()
    for group_stats in filtered_stats.values():
        all_locations.update(group_stats.index)

    # åªä¿ç•™åœ¨è‡³å°‘ä¸€ä¸ªç»„ä¸­å æ¯”>2%çš„å®šä½
    significant_locations = set()
    for loc in all_locations:
        for group, group_stats in filtered_stats.items():
            if loc in group_stats:
                percentage = group_stats[loc] / filtered_totals[group] * 100
                if percentage > 2:
                    significant_locations.add(loc)
                    break

    if not significant_locations:
        print("âŒ No significant subcellular localizations found")
        return

    # åˆ›å»ºçŸ©é˜µ
    groups = essential_groups
    locations = sorted(significant_locations)

    matrix = []
    for group in groups:
        if group in filtered_stats:
            row = []
            for loc in locations:
                count = filtered_stats[group].get(loc, 0)
                percentage = count / filtered_totals[group] * 100 if filtered_totals[group] > 0 else 0
                row.append(percentage)
            matrix.append(row)

    # åˆ›å»ºçƒ­å›¾
    plt.figure(figsize=(12, 8))

    # å¤„ç†å®šä½åç§°ï¼Œç¼©çŸ­è¿‡é•¿çš„åç§°
    short_locations = []
    for loc in locations:
        if len(loc) > 25:
            short_locations.append(loc[:22] + '...')
        else:
            short_locations.append(loc)

    sns.heatmap(
        matrix,
        xticklabels=short_locations,
        yticklabels=[group for group in groups if group in filtered_stats],
        annot=False,  # ä¸æ˜¾ç¤ºæ•°å­—
        cmap='Reds',
        cbar_kws={'label': 'Percentage (%)'},
        linewidths=0.5
    )

    plt.title('Subcellular Localization Distribution\nEssential Protein Groups',
             fontsize=14, fontweight='bold')
    plt.xlabel('Subcellular Localization', fontsize=12, fontweight='bold')
    plt.ylabel('Essential Protein Groups', fontsize=12, fontweight='bold')
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)

    plt.tight_layout()
    plt.savefig('../results/subcellular_localization_heatmap.png',
               dpi=300, bbox_inches='tight')
    plt.close()  # å…³é—­å›¾å½¢ï¼Œä¸æ˜¾ç¤º

def create_go_enrichment_plot(go_results):
    """åˆ›å»ºGOç»†èƒç»„åˆ†å¯Œé›†å›¾"""
    if not go_results or len(go_results['significant_results']) == 0:
        print("âŒ No significant GO enrichment results to plot")
        return

    print("ğŸ¨ Creating GO cellular component enrichment plot...")

    results = go_results['significant_results']

    # è·å–æ¯ä¸ªç»„çš„å‰8ä¸ªterm
    plot_data = []
    for group in results['group'].unique():
        group_results = results[results['group'] == group].head(8)
        plot_data.append(group_results)

    if not plot_data:
        return

    plot_df = pd.concat(plot_data).reset_index(drop=True)

    # åˆ›å»ºæ°”æ³¡å›¾
    fig, ax = plt.subplots(figsize=(14, 10))

    groups = plot_df['group'].unique()
    y_pos = 0

    for group in groups:
        group_data = plot_df[plot_df['group'] == group]
        n_terms = len(group_data)

        positions = range(y_pos, y_pos + n_terms)

        # ç»˜åˆ¶æ°”æ³¡
        scatter = ax.scatter(
            group_data['fold_enrichment'],
            positions,
            s=group_data['group_with_term'] * 30,  # å¤§å°åŸºäºè›‹ç™½è´¨æ•°é‡
            c=COLORS.get(group, '#999999'),
            alpha=0.7,
            edgecolors='black',
            linewidth=0.5,
            label=group
        )

        # æ·»åŠ æ ‡ç­¾
        for i, (_, row) in enumerate(group_data.iterrows()):
            term_name = row['go_term'][:35] + '...' if len(row['go_term']) > 35 else row['go_term']
            ax.text(0.1, positions[i], f"{group}: {term_name}",
                   fontsize=8, va='center', ha='left')

        y_pos += n_terms + 1

    ax.set_xlabel('Fold Enrichment', fontsize=12, fontweight='bold')
    ax.set_title('GO Cellular Component Enrichment\nNeutrophil Protein Groups',
                fontsize=14, fontweight='bold')
    ax.set_xscale('log')
    ax.axvline(x=1.5, color='red', linestyle='--', alpha=0.5)
    ax.set_yticks([])
    ax.grid(True, alpha=0.3, axis='x')

    plt.tight_layout()
    plt.savefig('../results/go_cellular_component_enrichment.png',
               dpi=300, bbox_inches='tight')
    plt.close()  # å…³é—­å›¾å½¢ï¼Œä¸æ˜¾ç¤º

def create_localization_comparison_plot(subcellular_results):
    """åˆ›å»ºå®šä½æ¯”è¾ƒå›¾"""
    if not subcellular_results:
        return

    print("ğŸ¨ Creating subcellular localization comparison plot...")

    stats = subcellular_results['stats']
    totals = subcellular_results['totals']

    # åªä¿ç•™å¿…éœ€è›‹ç™½è´¨ç»„åˆ«ï¼Œæ’é™¤å…±åŒéå¿…éœ€
    essential_groups = [
        'Commonly Essential',
        'Human-Specific Essential',
        'Immune-Specific Essential'
    ]

    # è¿‡æ»¤å‡ºå¿…éœ€ç»„åˆ«çš„æ•°æ®
    filtered_stats = {group: stats[group] for group in essential_groups if group in stats}
    filtered_totals = {group: totals[group] for group in essential_groups if group in totals}

    if not filtered_stats:
        print("âŒ No essential protein groups found")
        return

    # ç»Ÿè®¡æ‰€æœ‰å®šä½çš„æ€»é¢‘æ¬¡ï¼ˆä»…é’ˆå¯¹å¿…éœ€ç»„åˆ«ï¼‰
    location_totals = Counter()
    for group_stats in filtered_stats.values():
        for loc, count in group_stats.items():
            location_totals[loc] += count

    # é€‰æ‹©å‰10ä¸ªæœ€å¸¸è§çš„å®šä½
    top_locations = [loc for loc, count in location_totals.most_common(10)]

    # å‡†å¤‡æ•°æ®
    plot_data = []

    for group in essential_groups:
        if group in filtered_stats:
            group_stats = filtered_stats[group]
            group_total = filtered_totals[group]

            for loc in top_locations:
                count = group_stats.get(loc, 0)
                percentage = count / group_total * 100 if group_total > 0 else 0

                plot_data.append({
                    'Group': group,
                    'Location': loc,
                    'Percentage': percentage,
                    'Count': count
                })

    plot_df = pd.DataFrame(plot_data)

    # åˆ›å»ºåˆ†ç»„æŸ±çŠ¶å›¾
    plt.figure(figsize=(14, 8))

    # ä½¿ç”¨seabornåˆ›å»ºåˆ†ç»„æŸ±çŠ¶å›¾
    sns.barplot(
        data=plot_df,
        x='Location',
        y='Percentage',
        hue='Group',
        palette=COLORS
    )

    plt.title('Subcellular Localization Distribution\nEssential Protein Groups',
             fontsize=14, fontweight='bold')
    plt.xlabel('Subcellular Localization', fontsize=12, fontweight='bold')
    plt.ylabel('Percentage (%)', fontsize=12, fontweight='bold')
    plt.xticks(rotation=45, ha='right')
    plt.legend(title='Essential Protein Groups', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    plt.savefig('../results/subcellular_localization_comparison.png',
               dpi=300, bbox_inches='tight')
    plt.close()  # å…³é—­å›¾å½¢ï¼Œä¸æ˜¾ç¤º

def save_results(subcellular_results, go_results):
    """ä¿å­˜åˆ†æç»“æœ"""
    print("ğŸ’¾ Saving analysis results...")

    # ä¿å­˜äºšç»†èƒå®šä½åˆ†å¸ƒ
    if subcellular_results:
        stats = subcellular_results['stats']
        totals = subcellular_results['totals']

        # åˆ›å»ºåˆ†å¸ƒè¡¨
        distribution_data = []
        for group in stats.keys():
            for loc, count in stats[group].items():
                total = totals[group]
                percentage = count / total * 100
                distribution_data.append({
                    'group': group,
                    'location': loc,
                    'count': count,
                    'total': total,
                    'percentage': percentage
                })

        distribution_df = pd.DataFrame(distribution_data)
        distribution_df.to_csv('../results/subcellular_localization_distribution.csv', index=False)
        print("âœ“ Saved subcellular localization distribution")

    # ä¿å­˜GOå¯Œé›†ç»“æœ
    if go_results:
        # ä¿å­˜æ‰€æœ‰ç»“æœ
        go_results['all_results'].to_csv('../results/go_cellular_component_all_results.csv', index=False)

        # ä¿å­˜æ˜¾è‘—ç»“æœ
        if len(go_results['significant_results']) > 0:
            go_results['significant_results'].to_csv('../results/go_cellular_component_significant.csv', index=False)
            print("âœ“ Saved GO cellular component enrichment results")

def generate_report(subcellular_results, go_results, localization_data):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    print("ğŸ“ Generating analysis report...")

    report = []
    report.append("# äºšç»†èƒå®šä½å’ŒGOç»†èƒç»„åˆ†åˆ†ææŠ¥å‘Š")
    report.append("## ä¸­æ€§ç²’ç»†èƒè›‹ç™½è´¨åˆ†ç»„æ¯”è¾ƒ\n")

    # æ•°æ®æ¦‚è§ˆ
    total_proteins = len(localization_data)
    with_subcellular = len(localization_data[localization_data['subcellular_location'] != ''])
    with_go_cc = len(localization_data[localization_data['go_cellular_component'].apply(len) > 0])

    report.append("### æ•°æ®æ¦‚è§ˆ")
    report.append(f"- **æ€»è›‹ç™½è´¨æ•°é‡**: {total_proteins}")
    report.append(f"- **æœ‰äºšç»†èƒå®šä½ä¿¡æ¯**: {with_subcellular} ({with_subcellular/total_proteins*100:.1f}%)")
    report.append(f"- **æœ‰GOç»†èƒç»„åˆ†ä¿¡æ¯**: {with_go_cc} ({with_go_cc/total_proteins*100:.1f}%)\n")

    # è›‹ç™½è´¨ç»„åˆ«åˆ†å¸ƒ
    report.append("### è›‹ç™½è´¨ç»„åˆ«åˆ†å¸ƒ")
    for group, count in localization_data['group'].value_counts().items():
        report.append(f"- **{group}**: {count} ä¸ªè›‹ç™½è´¨")
    report.append("")

    # äºšç»†èƒå®šä½åˆ†æ
    if subcellular_results:
        report.append("### äºšç»†èƒå®šä½åˆ†å¸ƒ")
        stats = subcellular_results['stats']
        totals = subcellular_results['totals']

        for group in stats.keys():
            group_stats = stats[group]
            total = totals[group]

            report.append(f"\n**{group}** ({total} ä¸ªè›‹ç™½è´¨):")
            for loc, count in group_stats.head(5).items():
                percentage = count / total * 100
                report.append(f"- {loc}: {count} ({percentage:.1f}%)")

    # GOç»†èƒç»„åˆ†å¯Œé›†åˆ†æ
    if go_results and len(go_results['significant_results']) > 0:
        report.append("\n### GOç»†èƒç»„åˆ†å¯Œé›†åˆ†æ")
        significant_results = go_results['significant_results']

        report.append(f"- **æ˜¾è‘—å¯Œé›†çš„GO term**: {len(significant_results)}")

        for group in significant_results['group'].unique():
            group_results = significant_results[significant_results['group'] == group]
            report.append(f"\n**{group}** ({len(group_results)} ä¸ªå¯Œé›†term):")

            for _, row in group_results.head(5).iterrows():
                report.append(f"- {row['go_term']}: FC={row['fold_enrichment']:.2f}, "
                            f"P_adj={row['adj_p_value']:.2e}")
    else:
        report.append("\n### GOç»†èƒç»„åˆ†å¯Œé›†åˆ†æ")
        report.append("- æœªå‘ç°æ˜¾è‘—å¯Œé›†çš„GOç»†èƒç»„åˆ†term")

    # ä¸»è¦å‘ç°
    report.append("\n### ä¸»è¦å‘ç°")

    if subcellular_results:
        stats = subcellular_results['stats']
        totals = subcellular_results['totals']

        # æ‰¾å‡ºæ¯ä¸ªç»„æœ€ä¸»è¦çš„å®šä½
        for group in stats.keys():
            group_stats = stats[group]
            if len(group_stats) > 0:
                main_loc = group_stats.index[0]
                main_count = group_stats.iloc[0]
                total = totals[group]
                percentage = main_count / total * 100
                report.append(f"- **{group}**ä¸»è¦å®šä½äº{main_loc} ({percentage:.1f}%)")

    if go_results and len(go_results['significant_results']) > 0:
        significant_results = go_results['significant_results']
        # ç»Ÿè®¡æ¯ç»„çš„å¯Œé›†æ•°é‡
        group_enrichment_counts = significant_results['group'].value_counts()
        for group, count in group_enrichment_counts.items():
            report.append(f"- **{group}**æœ‰{count}ä¸ªæ˜¾è‘—å¯Œé›†çš„GOç»†èƒç»„åˆ†term")

    # ç”Ÿç‰©å­¦æ„ä¹‰
    report.append("\n### ç”Ÿç‰©å­¦æ„ä¹‰")
    report.append("- ä¸åŒè›‹ç™½è´¨ç»„åˆ«åœ¨äºšç»†èƒå®šä½ä¸Šè¡¨ç°å‡ºæ˜æ˜¾å·®å¼‚")
    report.append("- è¿™äº›å·®å¼‚åæ˜ äº†ä¸åŒè›‹ç™½è´¨åœ¨ç»†èƒåŠŸèƒ½ä¸­çš„ç‰¹å®šè§’è‰²")
    report.append("- å®šä½å·®å¼‚å¯èƒ½ä¸è›‹ç™½è´¨çš„å¿…éœ€æ€§ç‰¹å¾ç›¸å…³")
    report.append("- GOç»†èƒç»„åˆ†å¯Œé›†åˆ†ææ­ç¤ºäº†ç»„åˆ«ç‰¹å¼‚æ€§çš„åŠŸèƒ½åŒºå®¤åå¥½")

    # ä¿å­˜æŠ¥å‘Š
    with open('../results/subcellular_localization_report.md', 'w', encoding='utf-8') as f:
        f.write('\n'.join(report))

    print("âœ“ Report saved: ../results/subcellular_localization_report.md")

def main():
    """è¿è¡Œå®Œæ•´åˆ†æ"""

    print("=" * 60)
    print("SUBCELLULAR LOCALIZATION AND GO CELLULAR COMPONENT ANALYSIS")
    print("=" * 60)

    try:
        # åŠ è½½æ•°æ®
        protein_groups, uniprot_annotations = load_data()
        if protein_groups is None or uniprot_annotations is None:
            return

        # å¤„ç†å®šä½æ•°æ®
        localization_data = process_localization_data(protein_groups, uniprot_annotations)

        # è¿›è¡Œåˆ†æ
        print("\nğŸ” Performing analyses...")
        subcellular_results = analyze_subcellular_distribution(localization_data)
        go_results = analyze_go_cellular_component_enrichment(localization_data)

        # åˆ›å»ºå¯è§†åŒ–
        print("\nğŸ¨ Creating visualizations...")
        create_subcellular_heatmap(subcellular_results)
        create_go_enrichment_plot(go_results)
        create_localization_comparison_plot(subcellular_results)

        # ä¿å­˜ç»“æœå’Œç”ŸæˆæŠ¥å‘Š
        print("\nğŸ’¾ Saving results...")
        save_results(subcellular_results, go_results)
        generate_report(subcellular_results, go_results, localization_data)

        print("=" * 60)
        print("Analysis completed! Results saved in ../results/ directory")
        print("Generated files:")
        print("  â€¢ subcellular_localization_heatmap.png")
        print("  â€¢ go_cellular_component_enrichment.png")
        print("  â€¢ subcellular_localization_comparison.png")
        print("  â€¢ subcellular_localization_distribution.csv")
        print("  â€¢ go_cellular_component_significant.csv")
        print("  â€¢ subcellular_localization_report.md")
        print("=" * 60)

    except Exception as e:
        print(f"âŒ An error occurred during analysis: {e}")
        print("   Please check your data files and try again.")

if __name__ == "__main__":
    main()